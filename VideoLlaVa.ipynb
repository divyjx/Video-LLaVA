{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5eAOh7yXrE1"
      },
      "outputs": [],
      "source": [
        "########################## CONDA_INSTALLATION ##########################\n",
        "# !wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "# !chmod +x ./Miniconda3-latest-Linux-x86_64.sh\n",
        "# !bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "# !rm ./Miniconda3-latest-Linux-x86_64.sh\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5RfEqshX37s"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/divyjx/Video-LLaVA\n",
        "# %cd Video-LLaVA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emABm1ssX2OO"
      },
      "outputs": [],
      "source": [
        "########################## CONDA_ENV_CREATION ##########################\n",
        "# %%shell\n",
        "# eval \"$(conda shell.bash hook)\"\n",
        "# conda create -n videollava python=3.10 -y\n",
        "# conda init --all\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-sWoTzUHA2Q"
      },
      "outputs": [],
      "source": [
        "###########CONDA_SETUP_FOR_EACH_CELL###################\n",
        "# %%shell\n",
        "# eval \"$(conda shell.bash hook)\"\n",
        "# conda activate videollava\n",
        "#######################################################\n",
        "\n",
        "!pip install --upgrade pip  # enable PEP 660 support\n",
        "!pip install -e .\n",
        "!pip install -e \".[train]\"\n",
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install decord opencv-python git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
        "!pip install tensorboardX\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs8fGqTzIv2z"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id= \"LanguageBind/Video-LLaVA-Pretrain-7B\", local_dir = 'checkpoints/Video-LLaVA-Pretrain-7B', local_dir_use_symlinks=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiYM73b58sYt"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_EEr16C7kE2Y"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import snapshot_download\n",
        "# snapshot_download(repo_id= \"liuhaotian/LLaVA-CC3M-Pretrain-595K\", local_dir = 'tuning_data', local_dir_use_symlinks=True, repo_type = 'dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HjfOCuQ-AXn"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id= \"divyjx/VideoLLaVA_dataset\", local_dir = 'tuning_data', local_dir_use_symlinks=True, repo_type = 'dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ot--lNZFiMy"
      },
      "outputs": [],
      "source": [
        "!ls tuning_data/merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPKv5HTflztv"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('tuning_data/images.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('llava_image_tune')\n",
        "\n",
        "# %cd ..\n",
        "# !rm tuning_data/images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64f-EIKEn7lo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
        "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4aGSh_2o7wG"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# with open('tuning_data/chat.json', 'r') as file:\n",
        "#     data = json.load(file)\n",
        "\n",
        "# for entry in data:\n",
        "#     entry['image'] = 'images/' + entry['image']\n",
        "\n",
        "# with open('tuning_data/chat_new.json', 'w') as file:\n",
        "#     json.dump(data, file, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnFEztBaqqj3"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# f = open('tuning_data/chat_new.json')\n",
        "# data = json.load(f)\n",
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNVeH3mdrIOr"
      },
      "outputs": [],
      "source": [
        "# !rm tuning_data/chat.json\n",
        "# !rm tuning_data/metadata.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLecA_EbpGv0"
      },
      "source": [
        "# Edit Script\n",
        "copy DATA_ROOT=\"image.... cell and then paste it in original file scripts/v1_5/finetune.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfjemE9xsTVb"
      },
      "outputs": [],
      "source": [
        "# change log\n",
        "# bf16 not supported => bf16 False\n",
        "# tf32 not supported => tf32 False\n",
        "# hugging face error => TRANSFORMERS_OFFLINE = 0\n",
        "# low ram error\n",
        "\n",
        "####### Do not run below cell  ########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VhWG364xDDY"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs_IoMvwGgXS"
      },
      "source": [
        "# modify finetune_final.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liXH5FUbv2U1",
        "outputId": "4955fcd8-958f-4ef7-b494-0eeb04b8bb6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting scripts/v1_5/finetune_final.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile scripts/v1_5/finetune_final.sh\n",
        "\n",
        "DATA_ROOT=\"data_root\"\n",
        "DATA_ROOT_IMAGE=\"images\"\n",
        "DATA_ROOT_VIDEO=\"videos\"\n",
        "\n",
        "HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=0 CUDA_VISIBLE_DEVICES=0,1,2,3 deepspeed llava/train/train_mem.py \\\n",
        "    --deepspeed ./scripts/zero2.json \\\n",
        "    --model_name_or_path lmsys/vicuna-7b-v1.5 \\\n",
        "    --version v1 \\\n",
        "    --data_path tuning_data/merged/merged_100.json \\\n",
        "    --video_folder ${DATA_ROOT_VIDEO} \\\n",
        "    --image_folder ${DATA_ROOT_IMAGE} \\\n",
        "    --X \"Video\" \"Image\" \\\n",
        "    --video_tower LanguageBind/LanguageBind_Video_merge \\\n",
        "    --image_tower LanguageBind/LanguageBind_Image \\\n",
        "    --pretrain_mm_mlp_adapter checkpoints/Video-LLaVA-Pretrain-7B/mm_projector.bin \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_x_start_end False \\\n",
        "    --mm_use_x_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 True \\\n",
        "    --output_dir ./checkpoints/output/Video-LLaVA-7B \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --dataloader_num_workers 8 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --report_to tensorboard \\\n",
        "    --cache_dir \"./cache_dir\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKT8jjuTHG2A"
      },
      "source": [
        "# edit zero2.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYIy4pc_Gts5",
        "outputId": "6bf9f110-7e8b-40fc-8d0a-e394adb47920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting scripts/zero2.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile scripts/zero2.json\n",
        "{\n",
        "    \"fp16\": {\n",
        "        \"enabled\": \"auto\",\n",
        "        \"loss_scale\": 0,\n",
        "        \"loss_scale_window\": 1000,\n",
        "        \"initial_scale_power\": 16,\n",
        "        \"hysteresis\": 2,\n",
        "        \"min_loss_scale\": 1\n",
        "    },\n",
        "    \"bf16\": {\n",
        "        \"enabled\": \"auto\"\n",
        "    },\n",
        "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
        "    \"train_batch_size\": \"auto\",\n",
        "    \"gradient_accumulation_steps\": \"auto\",\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,\n",
        "        \"overlap_comm\": true,\n",
        "        \"contiguous_gradients\": true,\n",
        "        \"sub_group_size\": 1e9,\n",
        "        \"reduce_bucket_size\": \"auto\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fjvZQ29ZvhO9",
        "outputId": "ee325975-6c94-4b07-f7af-4312980093ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 3: fg: no job control\n",
            "[2023-12-14 16:18:36,840] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-14 16:18:39,161] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0\n",
            "[2023-12-14 16:18:39,161] [INFO] [runner.py:555:main] cmd = /usr/local/envs/videollava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --deepspeed ./scripts/zero2.json --model_name_or_path lmsys/vicuna-7b-v1.5 --version v1 --data_path tuning_data/merged/merged_10000.json --video_folder videos --image_folder images --X Video Image --video_tower LanguageBind/LanguageBind_Video_merge --image_tower LanguageBind/LanguageBind_Image --pretrain_mm_mlp_adapter checkpoints/Video-LLaVA-Pretrain-7B/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_x_start_end False --mm_use_x_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 False --output_dir ./checkpoints/output/Video-LLaVA-7B --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 False --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 8 --lazy_preprocess True --report_to tensorboard --cache_dir ./cache_dir\n",
            "[2023-12-14 16:18:40,515] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2023-12-14 16:18:42,366] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-12-14 16:18:42,367] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2023-12-14 16:18:42,367] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2023-12-14 16:18:42,367] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2023-12-14 16:18:42,367] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2023-12-14 16:18:42,367] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2023-12-14 16:18:45,157] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/videollava/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "/content/Video-LLaVA/llava/train/llama_flash_attn_monkey_patch.py:108: UserWarning: Flash attention is only supported on A100 or H100 GPU during training due to head dim > 64 backward.ref: https://github.com/HazyResearch/flash-attention/issues/190#issuecomment-1523359593\n",
            "  warnings.warn(\n",
            "[2023-12-14 16:18:46,192] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
            "[2023-12-14 16:18:46,192] [INFO] [comm.py:594:init_distributed] cdb=None\n",
            "[2023-12-14 16:18:46,192] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "config.json: 100% 615/615 [00:00<00:00, 3.26MB/s]\n",
            "You are using a model of type llama to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 69.5MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.98G [00:00<00:57, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 52.4M/9.98G [00:00<00:43, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 83.9M/9.98G [00:00<00:39, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 115M/9.98G [00:00<00:38, 258MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.98G [00:00<00:38, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.98G [00:00<00:40, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.98G [00:00<00:41, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 241M/9.98G [00:01<00:42, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 273M/9.98G [00:01<00:42, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.98G [00:01<00:42, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 336M/9.98G [00:01<00:41, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 367M/9.98G [00:01<00:43, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 398M/9.98G [00:01<00:45, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.98G [00:01<00:43, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 461M/9.98G [00:02<00:42, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.98G [00:02<00:45, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.98G [00:02<00:47, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 545M/9.98G [00:02<00:47, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 566M/9.98G [00:02<00:48, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.98G [00:03<01:30, 104MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 608M/9.98G [00:03<01:19, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 629M/9.98G [00:03<01:11, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 650M/9.98G [00:03<01:09, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 671M/9.98G [00:03<01:03, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 692M/9.98G [00:03<00:58, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.98G [00:03<00:54, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 744M/9.98G [00:03<00:50, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 765M/9.98G [00:04<00:48, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 797M/9.98G [00:04<00:45, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 818M/9.98G [00:04<00:46, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.98G [00:04<00:47, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 860M/9.98G [00:04<00:50, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 881M/9.98G [00:04<00:51, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 912M/9.98G [00:04<00:46, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 944M/9.98G [00:04<00:43, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 975M/9.98G [00:05<00:43, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 996M/9.98G [00:05<00:46, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.02G/9.98G [00:05<00:46, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:05<00:46, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:05<00:44, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:08<05:10, 28.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:08<03:32, 41.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:08<02:54, 50.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:08<02:27, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.98G [00:08<02:03, 71.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:08<01:29, 97.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:08<01:15, 116MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.27G/9.98G [00:09<01:08, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:09<00:57, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:09<00:50, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [00:09<00:45, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.39G/9.98G [00:09<00:43, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.43G/9.98G [00:09<00:40, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [00:09<00:38, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [00:10<00:38, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.52G/9.98G [00:10<00:36, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [00:10<00:35, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.58G/9.98G [00:10<00:35, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [00:10<00:34, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [00:10<00:34, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.68G/9.98G [00:10<00:33, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.71G/9.98G [00:10<00:33, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [00:11<00:33, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [00:11<00:48, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [00:11<00:42, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [00:11<00:42, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:11<00:40, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [00:11<00:39, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:12<00:37, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [00:12<00:37, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [00:12<00:36, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [00:12<00:35, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [00:12<00:35, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [00:12<00:33, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [00:12<00:32, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.15G/9.98G [00:12<00:31, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.18G/9.98G [00:13<00:30, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [00:13<00:42, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [00:13<00:43, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.26G/9.98G [00:13<00:44, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [00:17<05:40, 22.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.31G/9.98G [00:17<04:23, 29.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [00:17<03:24, 37.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.35G/9.98G [00:17<02:39, 47.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [00:17<01:52, 67.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [00:17<01:24, 89.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.44G/9.98G [00:17<01:06, 113MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.47G/9.98G [00:18<00:57, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [00:18<00:49, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [00:18<00:48, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [00:18<00:46, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [00:18<00:40, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [00:18<00:39, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.98G [00:18<00:36, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [00:19<00:34, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [00:19<00:32, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [00:19<00:31, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [00:19<00:30, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [00:19<00:29, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [00:19<00:29, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [00:19<00:28, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [00:19<00:28, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [00:20<00:28, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [00:20<00:28, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [00:20<00:28, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [00:20<00:28, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [00:20<00:27, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [00:20<00:28, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [00:20<00:29, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.98G [00:21<00:29, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [00:22<01:29, 76.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [00:22<01:12, 93.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.24G/9.98G [00:22<01:12, 93.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [00:22<01:03, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [00:22<00:51, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [00:22<00:43, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.34G/9.98G [00:22<00:42, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.37G/9.98G [00:23<00:55, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [00:23<00:49, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [00:23<00:40, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [00:23<00:34, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [00:23<00:31, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [00:23<00:28, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.54G/9.98G [00:24<00:32, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.58G/9.98G [00:24<00:31, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [00:27<03:21, 31.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [00:27<02:28, 42.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [00:27<02:07, 49.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [00:27<01:47, 58.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [00:27<01:27, 71.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.73G/9.98G [00:27<01:04, 96.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [00:27<00:55, 111MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.77G/9.98G [00:28<00:49, 125MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [00:28<00:46, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.82G/9.98G [00:28<00:42, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.84G/9.98G [00:28<00:39, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [00:28<00:33, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.90G/9.98G [00:28<00:32, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [00:28<00:34, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.94G/9.98G [00:28<00:34, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [00:29<00:33, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [00:29<00:33, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [00:30<02:04, 47.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.03G/9.98G [00:32<03:53, 25.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.98G [00:32<03:03, 32.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.07G/9.98G [00:32<02:19, 42.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [00:32<01:34, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.13G/9.98G [00:32<01:08, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [00:32<00:54, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [00:33<00:50, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.98G [00:33<00:41, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.24G/9.98G [00:33<00:37, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.98G [00:33<00:49, 116MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [00:33<00:39, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.98G [00:33<00:33, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.98G [00:33<00:29, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.38G/9.98G [00:34<00:30, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.41G/9.98G [00:34<00:28, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.45G/9.98G [00:34<00:27, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.48G/9.98G [00:37<02:44, 33.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.51G/9.98G [00:37<02:04, 44.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [00:37<01:47, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [00:37<01:19, 68.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [00:39<02:23, 37.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.60G/9.98G [00:39<01:57, 45.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [00:39<01:35, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [00:39<01:19, 67.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.67G/9.98G [00:39<01:04, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.70G/9.98G [00:39<00:48, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.73G/9.98G [00:39<00:39, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.76G/9.98G [00:39<00:32, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.79G/9.98G [00:40<00:29, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.82G/9.98G [00:40<00:26, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.85G/9.98G [00:40<00:25, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.89G/9.98G [00:40<00:24, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [00:40<00:22, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [00:40<00:21, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.98G/9.98G [00:40<00:21, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.01G/9.98G [00:41<00:21, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.04G/9.98G [00:41<00:21, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.08G/9.98G [00:41<00:21, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.11G/9.98G [00:41<00:23, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.14G/9.98G [00:41<00:25, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.16G/9.98G [00:41<00:25, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [00:42<01:14, 64.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.98G [00:42<00:55, 85.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.98G [00:43<00:43, 108MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.98G [00:43<00:35, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [00:43<00:34, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.98G [00:43<00:32, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.34G/9.98G [00:43<00:42, 110MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [00:43<00:38, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [00:44<00:33, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.98G [00:44<00:28, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [00:44<00:23, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.98G [00:44<00:22, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [00:44<00:22, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.54G/9.98G [00:44<00:21, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.98G [00:47<01:59, 36.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.59G/9.98G [00:47<01:38, 44.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.61G/9.98G [00:47<01:24, 51.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.64G/9.98G [00:47<01:01, 70.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [00:47<00:50, 84.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.98G [00:47<00:39, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [00:47<00:36, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.74G/9.98G [00:48<00:32, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.77G/9.98G [00:48<00:27, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.80G/9.98G [00:48<00:23, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.83G/9.98G [00:48<00:21, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.86G/9.98G [00:48<00:19, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.89G/9.98G [00:48<00:18, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [00:48<00:17, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [00:49<00:17, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.99G/9.98G [00:49<00:16, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.02G/9.98G [00:49<00:16, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [00:49<00:16, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [00:49<00:16, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.11G/9.98G [00:49<00:15, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [00:49<00:16, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [00:49<00:15, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.21G/9.98G [00:50<00:16, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.24G/9.98G [00:50<00:15, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [00:50<00:15, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [00:50<00:15, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.33G/9.98G [00:50<00:15, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.36G/9.98G [00:50<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [00:50<00:14, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.43G/9.98G [00:50<00:14, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.46G/9.98G [00:51<00:14, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.49G/9.98G [00:51<00:14, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.52G/9.98G [00:51<00:14, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.55G/9.98G [00:51<00:13, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.59G/9.98G [00:51<00:13, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.62G/9.98G [00:51<00:13, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [00:51<00:13, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.68G/9.98G [00:51<00:13, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [00:52<00:12, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [00:52<00:13, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [00:52<00:13, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.81G/9.98G [00:52<00:13, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.84G/9.98G [00:52<00:14, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.87G/9.98G [00:52<00:13, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [00:52<00:13, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.93G/9.98G [00:53<00:13, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.96G/9.98G [00:53<00:13, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.99G/9.98G [00:53<00:12, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [00:53<00:12, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [00:53<00:12, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.09G/9.98G [00:53<00:12, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.12G/9.98G [00:53<00:11, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [00:53<00:11, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.18G/9.98G [00:54<00:11, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.21G/9.98G [00:54<00:11, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.25G/9.98G [00:54<00:13, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [00:54<00:13, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [00:57<01:21, 32.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.33G/9.98G [00:57<00:59, 44.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.98G [00:57<00:51, 51.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [00:57<00:37, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.98G [00:57<00:28, 90.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [00:57<00:22, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [00:58<00:20, 122MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [00:58<00:17, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [00:58<00:14, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [00:58<00:13, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [00:58<00:12, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [00:58<00:11, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [00:58<00:10, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [00:59<00:10, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.73G/9.98G [00:59<00:09, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [00:59<00:09, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [00:59<00:09, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [00:59<00:09, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.85G/9.98G [00:59<00:08, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [00:59<00:08, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [00:59<00:08, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [01:00<00:08, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [01:00<00:08, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [01:00<00:08, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [01:00<00:08, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [01:00<00:08, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [01:00<00:08, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [01:00<00:08, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [01:01<00:07, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [01:01<00:07, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.23G/9.98G [01:01<00:07, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [01:01<00:07, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [01:01<00:07, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.33G/9.98G [01:01<00:06, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [01:02<00:09, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [01:02<00:08, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [01:02<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [01:02<00:07, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [01:02<00:06, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [01:02<00:06, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [01:02<00:06, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [01:02<00:06, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [01:03<00:06, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [01:03<00:06, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [01:03<00:05, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [01:03<00:05, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.73G/9.98G [01:03<00:05, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [01:03<00:05, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [01:03<00:04, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [01:04<00:04, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [01:04<00:04, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [01:04<00:04, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [01:04<00:04, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [01:04<00:04, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [01:04<00:04, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [01:04<00:03, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [01:04<00:03, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.08G/9.98G [01:05<00:03, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [01:05<00:03, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [01:05<00:03, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [01:05<00:03, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [01:05<00:03, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [01:05<00:03, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [01:05<00:03, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [01:06<00:02, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [01:07<00:08, 71.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [01:07<00:07, 83.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [01:07<00:06, 97.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [01:07<00:04, 120MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.43G/9.98G [01:07<00:04, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [01:07<00:03, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [01:07<00:03, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [01:08<00:02, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [01:08<00:02, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [01:08<00:02, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.57G/9.98G [01:08<00:02, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.59G/9.98G [01:12<00:19, 19.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [01:12<00:14, 25.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.64G/9.98G [01:12<00:10, 31.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [01:12<00:06, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.70G/9.98G [01:12<00:04, 66.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.98G [01:12<00:02, 89.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.75G/9.98G [01:12<00:02, 97.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.78G/9.98G [01:13<00:01, 122MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.81G/9.98G [01:13<00:01, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [01:13<00:00, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.98G [01:13<00:00, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.98G [01:13<00:00, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [01:13<00:00, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.95G/9.98G [01:13<00:00, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [01:14<00:00, 135MB/s]\n",
            "Downloading shards:  50% 1/2 [01:14<01:14, 74.19s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/3.50G [00:00<00:12, 275MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 62.9M/3.50G [00:00<00:12, 273MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 94.4M/3.50G [00:00<00:12, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 126M/3.50G [00:00<00:13, 254MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 157M/3.50G [00:00<00:13, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.50G [00:00<00:14, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.50G [00:03<01:25, 38.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.50G [00:03<01:05, 50.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 273M/3.50G [00:03<00:55, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 304M/3.50G [00:03<00:41, 77.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 336M/3.50G [00:03<00:31, 101MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 367M/3.50G [00:03<00:25, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 398M/3.50G [00:04<00:29, 107MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 430M/3.50G [00:04<00:23, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 461M/3.50G [00:04<00:19, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 493M/3.50G [00:04<00:17, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 524M/3.50G [00:04<00:16, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 556M/3.50G [00:04<00:16, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 587M/3.50G [00:04<00:15, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 619M/3.50G [00:05<00:14, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 650M/3.50G [00:05<00:13, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 682M/3.50G [00:05<00:13, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 713M/3.50G [00:05<00:13, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 744M/3.50G [00:05<00:13, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 776M/3.50G [00:05<00:13, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 797M/3.50G [00:06<00:14, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 818M/3.50G [00:06<00:15, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 839M/3.50G [00:06<00:14, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 860M/3.50G [00:06<00:14, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 881M/3.50G [00:08<01:07, 38.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 912M/3.50G [00:08<00:45, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 933M/3.50G [00:08<00:40, 62.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 965M/3.50G [00:08<00:29, 85.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 996M/3.50G [00:08<00:22, 110MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:08<00:18, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:08<00:17, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:09<00:16, 143MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.10G/3.50G [00:09<00:14, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:09<00:12, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.16G/3.50G [00:09<00:11, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:09<00:10, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:09<00:11, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:09<00:10, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:10<00:10, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:10<00:10, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.35G/3.50G [00:13<01:06, 32.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.37G/3.50G [00:13<00:54, 39.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.39G/3.50G [00:13<00:45, 46.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.43G/3.50G [00:13<00:32, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.46G/3.50G [00:13<00:24, 84.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.49G/3.50G [00:13<00:18, 107MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [00:13<00:18, 110MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.53G/3.50G [00:14<00:21, 93.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [00:14<00:16, 121MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.59G/3.50G [00:14<00:12, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [00:14<00:11, 158MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [00:14<00:10, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.67G/3.50G [00:14<00:10, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [00:15<00:09, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [00:18<01:10, 25.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.74G/3.50G [00:18<00:53, 32.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.77G/3.50G [00:18<00:36, 46.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [00:18<00:30, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.81G/3.50G [00:18<00:24, 68.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.85G/3.50G [00:18<00:18, 91.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.87G/3.50G [00:18<00:15, 107MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.89G/3.50G [00:19<00:14, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.91G/3.50G [00:19<00:13, 121MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.93G/3.50G [00:19<00:11, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [00:19<00:10, 142MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.98G/3.50G [00:19<00:09, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.01G/3.50G [00:19<00:08, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.03G/3.50G [00:19<00:07, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.06G/3.50G [00:19<00:07, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.08G/3.50G [00:20<00:08, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [00:20<00:08, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [00:20<00:07, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [00:23<00:57, 23.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.17G/3.50G [00:23<00:37, 35.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.19G/3.50G [00:23<00:30, 42.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.22G/3.50G [00:23<00:20, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [00:23<00:15, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.29G/3.50G [00:23<00:12, 98.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [00:23<00:10, 111MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [00:24<00:08, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.36G/3.50G [00:24<00:07, 149MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.39G/3.50G [00:24<00:06, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.42G/3.50G [00:24<00:05, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [00:24<00:05, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.49G/3.50G [00:24<00:04, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.52G/3.50G [00:24<00:04, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.55G/3.50G [00:24<00:04, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [00:25<00:04, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.61G/3.50G [00:25<00:03, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [00:25<00:03, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [00:25<00:03, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.71G/3.50G [00:25<00:03, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [00:25<00:03, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [00:26<00:10, 70.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.79G/3.50G [00:27<00:15, 46.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.81G/3.50G [00:28<00:12, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.83G/3.50G [00:28<00:10, 63.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.86G/3.50G [00:28<00:07, 85.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.89G/3.50G [00:28<00:05, 109MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [00:28<00:04, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.96G/3.50G [00:28<00:03, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.99G/3.50G [00:29<00:03, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [00:29<00:02, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [00:29<00:02, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.06G/3.50G [00:29<00:02, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.09G/3.50G [00:29<00:02, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [00:29<00:01, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.16G/3.50G [00:29<00:01, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.19G/3.50G [00:29<00:01, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [00:30<00:01, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [00:30<00:01, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.28G/3.50G [00:30<00:00, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.31G/3.50G [00:30<00:00, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.34G/3.50G [00:30<00:00, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.38G/3.50G [00:30<00:00, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.41G/3.50G [00:30<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.44G/3.50G [00:30<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.47G/3.50G [00:31<00:00, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [00:32<00:00, 106MB/s]\n",
            "Downloading shards: 100% 2/2 [01:47<00:00, 53.66s/it]\n",
            "[2023-12-14 16:21:02,060] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 7639\n",
            "[2023-12-14 16:21:02,064] [ERROR] [launch.py:321:sigkill_handler] ['/usr/local/envs/videollava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=0', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', 'lmsys/vicuna-7b-v1.5', '--version', 'v1', '--data_path', 'tuning_data/merged/merged_10000.json', '--video_folder', 'videos', '--image_folder', 'images', '--X', 'Video', 'Image', '--video_tower', 'LanguageBind/LanguageBind_Video_merge', '--image_tower', 'LanguageBind/LanguageBind_Image', '--pretrain_mm_mlp_adapter', 'checkpoints/Video-LLaVA-Pretrain-7B/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_x_start_end', 'False', '--mm_use_x_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'False', '--output_dir', './checkpoints/output/Video-LLaVA-7B', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'tensorboard', '--cache_dir', './cache_dir'] exits with return code = -9\n"
          ]
        },
        {
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ccd60ab4b017>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval \"$(conda shell.bash hook)\"\\nconda activate videollava\\n%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1\\n#######################################################\\nbash scripts/v1_5/finetune_final.sh\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'eval \"$(conda shell.bash hook)\"\nconda activate videollava\n%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1\n#######################################################\nbash scripts/v1_5/finetune_final.sh\n' returned non-zero exit status 247."
          ]
        }
      ],
      "source": [
        "###########CONDA_SETUP_FOR_EACH_CELL###################\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate videollava\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1\n",
        "#######################################################\n",
        "bash scripts/v1_5/finetune_final.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uploading checkpoints to hf\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=\"/checkpoints/output\",\n",
        "    repo_id=\"divyjx/VideoLLaVA_ckpt\",\n",
        "    repo_type=\"model\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moiPs5slLjol"
      },
      "outputs": [],
      "source": [
        "# |-Video-LLaVA\n",
        "# |--tuning_data\n",
        "# |--checkpoints\n",
        "# |--cache_dir\n",
        "# |--images\n",
        "# |--videos\n",
        "# |--inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbtNvJ8XI-Me"
      },
      "outputs": [],
      "source": [
        "# pasting here for backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60rQBIf5HYuk"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATA_ROOT=\"data_root\"\n",
        "DATA_ROOT_IMAGE=\"images\"\n",
        "DATA_ROOT_VIDEO=\"videos\"\n",
        "\n",
        "HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=0 CUDA_VISIBLE_DEVICES=0,1,2,3 deepspeed llava/train/train_mem.py \\\n",
        "    --deepspeed ./scripts/zero2.json \\\n",
        "    --model_name_or_path lmsys/vicuna-7b-v1.5 \\\n",
        "    --version v1 \\\n",
        "    --data_path tuning_data/merged/merged_10000.json \\\n",
        "    --video_folder ${DATA_ROOT_VIDEO} \\\n",
        "    --image_folder ${DATA_ROOT_IMAGE} \\\n",
        "    --X \"Video\" \"Image\" \\\n",
        "    --video_tower LanguageBind/LanguageBind_Video_merge \\\n",
        "    --image_tower LanguageBind/LanguageBind_Image \\\n",
        "    --pretrain_mm_mlp_adapter checkpoints/Video-LLaVA-Pretrain-7B/mm_projector.bin \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_x_start_end False \\\n",
        "    --mm_use_x_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 True \\\n",
        "    --output_dir ./checkpoints/output/Video-LLaVA-7B \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --dataloader_num_workers 8 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --report_to tensorboard \\\n",
        "    --cache_dir \"./cache_dir\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
