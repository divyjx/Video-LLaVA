{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn6DPjZwYCy5"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5eAOh7yXrE1"
      },
      "outputs": [],
      "source": [
        "########################## CONDA INSTALLATION ##########################\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x ./Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!rm ./Miniconda3-latest-Linux-x86_64.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5RfEqshX37s",
        "outputId": "7c0f2b23-d450-4f68-95bf-4100ac16ce91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Video-LLaVA'...\n",
            "remote: Enumerating objects: 306, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 306 (delta 44), reused 50 (delta 17), pack-reused 228\u001b[K\n",
            "Receiving objects: 100% (306/306), 69.77 MiB | 35.04 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "/content/Video-LLaVA\n"
          ]
        }
      ],
      "source": [
        "##################### CLONE THE REPOSITORY #######################\n",
        "!git clone https://github.com/divyjx/Video-LLaVA\n",
        "%cd Video-LLaVA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emABm1ssX2OO"
      },
      "outputs": [],
      "source": [
        "########################## CONDA ENVIRONMENT CREATION ##########################\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda create -n videollava python=3.10 -y\n",
        "conda init --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-sWoTzUHA2Q"
      },
      "outputs": [],
      "source": [
        "############################# DOWNLOAD REQUIRED LIBRARIES ##############################\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate videollava\n",
        "\n",
        "pip install --upgrade pip  # enable PEP 660 support\n",
        "pip install -e .\n",
        "pip install -e \".[train]\"\n",
        "pip install flash-attn --no-build-isolation\n",
        "pip install decord opencv-python git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
        "pip install tensorboardX\n",
        "pip install pycocoevalcap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs8fGqTzIv2z"
      },
      "outputs": [],
      "source": [
        "######################### DOWNLOAD MODEL ##########################\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# no trianing\n",
        "# snapshot_download(repo_id= \"LanguageBind/Video-LLaVA-7B\", local_dir = 'checkpoints/Video-LLaVA-7B', local_dir_use_symlinks=True)\n",
        "\n",
        "# trained on 10k samples\n",
        "# snapshot_download(repo_id= \"divyjx/VideoLLaVA10k\", local_dir = 'checkpoints/Video-LLaVA-7B', local_dir_use_symlinks=True)\n",
        "\n",
        "# trained on 200k samples (final model)\n",
        "snapshot_download(repo_id= \"divyjx/VideoLLaVA\", local_dir = 'checkpoints/Video-LLaVA-7B', local_dir_use_symlinks=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c6It0VjxDI-"
      },
      "outputs": [],
      "source": [
        "######################### DOWNLOAD DATASET #########################\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id= \"divyjx/VideoLLaVA_dataset\", local_dir = 'tuning_data', local_dir_use_symlinks=True, repo_type = 'dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6E_wUnJL8mG"
      },
      "source": [
        "# Batch Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYEvhhs7wqZq"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate videollava\n",
        "python inference.py --model-path \"checkpoints/Video-LLaVA-7B\" --instruct-path \"tuning_data/content_10.json\" --output-file-path \"output.json\" --video-folder \"videos\" --image-folder \"images\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ9tYV5A_n19"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br1G0v3han-_"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate videollava\n",
        "python eval.py --prediction-file-path \"output.json\" --eval-file-path \"eval.json\" --input-file-path \"tuning_data/content_10.json\" --type-of-data \"content\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
